{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "299af2aa-4b0a-424a-8591-e292a893ca9d",
   "metadata": {},
   "source": [
    "# Training a Modified LeNet CNN for Breast Cancer Image Classification and deploying on FPGA target, using HLS4ML.\n",
    "## Vaggelis Ananiadis, Supervisor: Prof. Karakonstantis G.\n",
    "#### ECE-284 - Processor Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce329290-0621-4ce5-992e-3343ce1d8dab",
   "metadata": {},
   "source": [
    "## Read Dataset, collect data paths and labels from directory structure and preprocess images\n",
    "#### Training dataset was taken from: \n",
    "https://www.kaggle.com/datasets/aryashah2k/breast-ultrasound-images-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed44cef-aeb0-4ff2-9a38-38cb1d3f1844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Config\n",
    "IMAGE_SIZE = (32, 32)\n",
    "NUM_CHANNELS = 1\n",
    "DATASET_PATH = 'dataset_grayscale'\n",
    "OUTPUT_PATH = 'training'\n",
    "TEST_SIZE = 0.15\n",
    "VAL_SIZE = 0.15\n",
    "AUGMENT_FACTOR = 1  # How many extra augmented versions to generate per image\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Load images and labels\n",
    "images = []\n",
    "labels = []\n",
    "class_names = sorted(os.listdir(DATASET_PATH))\n",
    "\n",
    "for label_index, class_name in enumerate(class_names):\n",
    "    class_path = os.path.join(DATASET_PATH, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    for file in os.listdir(class_path):\n",
    "        file_path = os.path.join(class_path, file)\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, IMAGE_SIZE)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        images.append(img)\n",
    "        labels.append(label_index)\n",
    "\n",
    "# Convert to arrays\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Stratified split into train/val/test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=VAL_SIZE + TEST_SIZE, stratify=y, random_state=42)\n",
    "val_ratio = VAL_SIZE / (VAL_SIZE + TEST_SIZE)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1 - val_ratio, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Data augmentation setup (only for training)\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "augmented_X = []\n",
    "augmented_y = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    x = X_train[i]\n",
    "    label = y_train[i]\n",
    "    x_expanded = np.expand_dims(x, axis=0)\n",
    "    gen = datagen.flow(x_expanded, batch_size=1)\n",
    "    for _ in range(AUGMENT_FACTOR):\n",
    "        aug = next(gen)[0]\n",
    "        augmented_X.append(aug)\n",
    "        augmented_y.append(label)\n",
    "\n",
    "# Combine original + augmented training data\n",
    "X_train_aug = np.concatenate([X_train] + [np.array(augmented_X)], axis=0)\n",
    "y_train_aug = np.concatenate([y_train] + [np.array(augmented_y)], axis=0)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_aug = to_categorical(y_train_aug, num_classes=len(class_names))\n",
    "y_val = to_categorical(y_val, num_classes=len(class_names))\n",
    "y_test = to_categorical(y_test, num_classes=len(class_names))\n",
    "\n",
    "# Save datasets\n",
    "np.save(os.path.join(OUTPUT_PATH, 'X_train_32.npy'), X_train_aug)\n",
    "np.save(os.path.join(OUTPUT_PATH, 'X_val_32.npy'), X_val)\n",
    "np.save(os.path.join(OUTPUT_PATH, 'X_test_32.npy'), X_test)\n",
    "np.save(os.path.join(OUTPUT_PATH, 'y_train.npy'), y_train_aug)\n",
    "np.save(os.path.join(OUTPUT_PATH, 'y_val.npy'), y_val)\n",
    "np.save(os.path.join(OUTPUT_PATH, 'y_test.npy'), y_test)\n",
    "np.save(os.path.join(OUTPUT_PATH, 'classes.npy'), np.array(class_names))\n",
    "\n",
    "print(\"Data saved to\", OUTPUT_PATH)\n",
    "print(f\"Train (augmented): {X_train_aug.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
